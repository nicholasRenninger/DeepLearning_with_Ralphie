{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNGgCsb3Xbp_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "rcParams['figure.figsize'] = 16, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vssQzo6JYIjQ"
   },
   "outputs": [],
   "source": [
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nng6C8M3-imA"
   },
   "source": [
    "We will train a classifier to learn the function $y=1\\{0<x<1\\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7sD0lc1YKx3"
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(low=-1, high=2, size=100)\n",
    "y = np.logical_and(x >= 0.0, x <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xii_v-XYmPH"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgGi-1z4U_AG"
   },
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3T2UgYJYnFf"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, C=999, tol=0.1).fit(\n",
    "    X=np.expand_dims(x, -1), \n",
    "    y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAQRv8-ZaJD6"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, \n",
    "         clf.intercept_ + clf.coef_[0] * x, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjlYuiUXcRz-"
   },
   "outputs": [],
   "source": [
    "clf.predict(np.expand_dims(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PG8QjtzL_DfX"
   },
   "outputs": [],
   "source": [
    "clf.score(np.expand_dims(x, -1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvVbwvitVC2V"
   },
   "source": [
    "# Neural network with a designed hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jIBcnUB_m3_"
   },
   "source": [
    "We are going to use the standard ingredients of a feed-forward network: linear transformations and ReLU activations.\n",
    "We can design a hidden layer by observing that $1\\{0<x<1\\} = 1-(1\\{x<0\\} + 1\\{x>1\\})$\n",
    "\n",
    "This gives us a hint as to what hidden units might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1eLFxNuddyX"
   },
   "outputs": [],
   "source": [
    "# Use two ReLU units\n",
    "h = np.stack([np.maximum(-x, 0.0), np.maximum(x-1, 0.0)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueZU9pk0dwqo"
   },
   "outputs": [],
   "source": [
    "plt.scatter(h[:,0], h[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgM9mdXBdyhm"
   },
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(random_state=0, C=999, tol=0.001).fit(\n",
    "    X=h, \n",
    "    y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDuTnVVTfxUT"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, clf2.predict_proba(h)[:,1], 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dev-C4mWl531"
   },
   "source": [
    "# Trained hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PliMFgFvl7zo"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "num_hidden = 2\n",
    "np.random.seed(1)\n",
    "w_hidden = tf.Variable(initial_value=np.random.rand(1, num_hidden) - 0.5, dtype=tf.float32)\n",
    "b_hidden = tf.Variable(initial_value=0, dtype=tf.float32)\n",
    "w_logistic = tf.Variable(initial_value=np.random.rand(num_hidden, 1) - 0.5, dtype=tf.float32)\n",
    "b_logistic = tf.Variable(initial_value = -0.1)\n",
    "model = [w_hidden, b_hidden, w_logistic, b_logistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvaILi2rnvgy"
   },
   "outputs": [],
   "source": [
    "x_tensor = tf.cast(np.expand_dims(x, -1), tf.float32)\n",
    "y_tensor = tf.cast(y, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHOMCpIbqAbg"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qU4w4vKkrGaO"
   },
   "outputs": [],
   "source": [
    "def GetProbability(x_tensor, w_hidden, b_hidden, w_logistic, b_logistic):\n",
    "  h = tf.nn.relu(tf.matmul(x_tensor, w_hidden) + b_hidden)\n",
    "  a = tf.matmul(h, w_logistic) + b_logistic\n",
    "  a = tf.clip_by_value(a, -10, 10)\n",
    "  p = tf.squeeze(1.0 / (1.0 + tf.exp(-a)))\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ow4dNXcpRKV"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def UpdateParameters(model):\n",
    "  with tf.GradientTape() as tape:\n",
    "    p = GetProbability(x_tensor, *model)\n",
    "    l = - y_tensor * tf.log(p) - (1 - y_tensor) * tf.log(1-p)\n",
    "    total_loss = tf.reduce_sum(l)\n",
    "  grads = tape.gradient(total_loss, model)\n",
    "  optimizer.apply_gradients(zip(grads, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eP6p7bI4ou2E"
   },
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "  UpdateParameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B43v9mQ3reeV"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXttuTUHovTU"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, GetProbability(x_tensor, *model).numpy(), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXIW1zGSrc2t"
   },
   "outputs": [],
   "source": [
    "h = tf.nn.relu(tf.matmul(x_tensor, w_hidden) + b_hidden)\n",
    "plt.scatter(h[:,0], h[:,1], c=y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZGP2qvif51ulmHx2YohXv",
   "collapsed_sections": [],
   "name": "Hidden feature.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": ""
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
