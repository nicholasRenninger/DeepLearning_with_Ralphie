{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"assignment_4.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ym5oRoUx7Bqx","colab_type":"text"},"source":["# Homework 4 - Regularization.\n","\n","***\n","**Name**: \n","***\n","\n","## Goal\n","\n","In this assignment you will be experimenting/reproducing results of the regularization techniques in [Dropout: A Simple Way to Prevent Neural Networks from\n","Overfitting](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf).  \n","1. Random Dropout\n","2. Max-norm constraint\n","\n","Specifically, try to reproduce (just close enough to) some of the MNIST results in section 6.1.1:\n","1. Dropout w/ logistic activation, 3 layers, 1024 units\n","2. Dropout w/ RELU activation, 3 layers, 1024 units\n","3. Dropout + max norm (norm is a hyperparameter, just try a few values), w/ RELU activation, 3 layers, 1024 units\n","\n","Resources:\n","- tf [tutorial on over/under-fitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)\n","- tf [Keras dense layer doc](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n","- tf [Keras constraints doc](https://www.tensorflow.org/api_docs/python/tf/keras/constraints)\n","\n","**Report your results & write a short summary of any findings.**\n","\n","## Bonus\n","Explore L1, L2 normalization (and appropriate model architecture in which these techniques may help), but don't burn too many CPU cycles.\n","\n","## Due date\n","\n","Wednesday - 04/08/2020\n","\n","## Note:\n","*p* in the paper refers to the present (*1 - dropout*) probability, whereas the tf.keras dropout layer *p* is the dropout probability."]},{"cell_type":"code","metadata":{"id":"u09LVxzd7Bq0","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkLBY0cj7Bq5","colab_type":"text"},"source":["### Initialization"]},{"cell_type":"code","metadata":{"id":"Vtv1qYNr7BrQ","colab_type":"code","colab":{}},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wqe9ju-M_zWX","colab_type":"code","colab":{}},"source":["img_rows, img_cols = 28, 28\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BHDJw2_hAAwL","colab_type":"text"},"source":["### Baseline model"]},{"cell_type":"code","metadata":{"id":"0txQkbLuAHoK","colab_type":"code","colab":{}},"source":["activation = 'sigmoid'\n","\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Flatten(input_shape=input_shape))\n","model.add(tf.keras.layers.Dense(800, activation=activation))\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XzU6SSkeAa7H","colab_type":"text"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"_7dCFvI8Gp-O","colab_type":"code","colab":{}},"source":["model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=25,\n","          verbose=1,\n","          validation_split=0.05)\n","score = model.evaluate(x_test, y_test, verbose=1)"],"execution_count":0,"outputs":[]}]}